\section{RepReMatch}
\label{sec:reprematch}

\begin{itemize}
	\item
	\SMatch{} does not work for general submodular valuations since we need to detect the set of lowest valuation.
	This is not possible independent of \(m\) [SF11].\todo{what exactly did SF11 show?}
\end{itemize}

First, we give a lower bound one the valuation of an agent \(i\) for her optimal items which still may be assigned to her in phase \phaseii.
\begin{lemma}
	\label{lem:induction}
	During phase \phaseii, each agent \(i \in \agents\) gets assigned a bundle \(\alloc[\phaseii] = \{ \asgd{1}, \dots, \asgd{\alloclen[\phaseii]} \}\).
	For all rounds \(r = 2, \dots, \alloclen[\phaseii]\), the following inequality about her set \(\attopt{r}\) of optimal and attainable items holds true:
	\begin{equation*}
		\valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r-1} ] \geq \remvalue* - \lostsetlen{2} \cdot \valuations[\asgd{1}] - \smashoperator{\sum_{r'=2}^{r-1}} \lostsetlen{r'} \cdot \valuations[ \asgd{r'} \given \asgd{1}, \dots, \asgd{r'-1} ] - \valuations[\asgd{1}, \dots, \asgd{r-1}],
	\end{equation*}
	where \(\lostsetlen{l}\) is the size of her set \(\lostset{l} \subset \attopt{l-1}\) of optimal items which were attainable in round \(l-1\) and were assigned to other agents in round \(l\), and \(\remvalue* = \valuations[\attopt{1}]\) is her valuation of attainable and optimal items during the first round.
\end{lemma}
\begin{proof}
	We prove the lemma by induction on the number \(r\) of rounds.
	In the beginning of the base case \(r=2\), agent \(i\) has already been assigned item \(\asgd{1}\) but not the items in set~\(\lostset{1}\).
	For each of the remaining optimal and attainable items~\(j\) in round \(1\), the marginal valuation \(\valuations[j \given \emptyset]\) over the empty set is at most \(\valuations[\asgd{1} \given \emptyset]\), as otherwise item~\(\asgd{1}\) would not have been assigned first.
	Furthermore, the marginal valuation \(\valuations[j \given \asgd{1}]\) over \(\{\asgd{1}\}\) is upper-bounded by \(\valuations[\asgd{1} \given \emptyset]\) due to the submodularity of valuations.
	During the round, a further \(\lostsetlen{2}\) out of these items are assigned to other agents, and item \(\asgd{2}\) is assigned to agent \(i\).
	We can bound the marginal valuation of the remaining optimal and attainable items in round \(2\) in the following way:
	\begin{caseintext}{1}{\(\asgd{1} \in \attopt{1}\)}
		It holds \(\valuations[ \attopt{2} \given \asgd{1} ] = \valuations[ \attopt{2} \cup \{\asgd{1}\} ] - \valuations[\asgd{1}] = \valuations[\attopt{1} \setminus \lostset{2}] -  \valuations[\asgd{1}]\).
	\end{caseintext}
	\begin{caseintext}{2}{\(\asgd{1} \notin \attopt{1}\)}
		Due to the monotonicity of valuations, it holds \(\valuations[ \attopt{2} \cup \{\asgd{1}\} ] \geq \valuations[ \attopt{2} ]\) and, therefore, \(\valuations[ \attopt{2} \given \asgd{1} ] \geq \valuations[ \attopt{2} ] - \valuations[\asgd{1}] = \valuations[\attopt{1} \setminus \lostset{2}] -  \valuations[\asgd{1}]\).
	\end{caseintext}
	\noindent
	In both cases, the base case is proved because
	\begin{align}
		\valuations[ \attopt{2} \given \asgd{1} ]
		&\geq \valuations[\attopt{1} \setminus \lostset{2}] -  \valuations[\asgd{1}] \\
		&\geq \valuations[ \attopt{2} ] - \valuations[\lostset{2}] - \valuations[\asgd{1}] \\
		&\geq \remvalue* - \lostsetlen{2} \valuations[\asgd{1}] - \valuations[\asgd{1}],
	\end{align}
	where the second inequality can be shown inductively with the definition of submodularity\todo{Do that or, alternatively, find a paper showing the other def.}, and the third inequality is due all \(\lostsetlen{2}\) items \(j\) in \(\lostset{2}\) being attainable but not assigned in round \(1\), implying \(\valuations[j] \leq \valuations[\asgd{1}]\).

	As induction hypothesis, we assume that the lemma is true for all rounds up to some \(r\).
	For the induction step \(r \to r+1\), we differentiate the same two cases again:
	\begin{caseintext}{1}{\(\asgd{r} \in \attopt{r}\)}
		Again we use the submodularity of valuations \todo{ditto} to obtain a lower bound on the marginal valuation of \(\attopt{r+1}\).
		\begin{align}
			\valuations[ \attopt{r+1} \given \asgd{1}, \dots, \asgd{r} ]
			&= \valuations[ \attopt{r+1} \cup \{\asgd{r}\} \given \asgd{1}, \dots, \asgd{r-1} ] - \valuations[ \asgd{r} \given \asgd{1}, \dots, \asgd{r-1} ] \\
			&= \valuations[ \attopt{r} \setminus \lostset{r+1} \given \asgd{1}, \dots, \asgd{r-1} ] - \valuations[ \asgd{r} \given \asgd{1}, \dots, \asgd{r-1} ] \\
			&\geq \begin{multlined}[t]
				\valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r-1} ] - \valuations[ \asgd{r} \given \asgd{1}, \dots, \asgd{r-1} ] \\
				- \valuations[ \lostset{r+1} \given \asgd{1}, \dots, \asgd{r-1} ]
			\end{multlined}
		\end{align}
	\end{caseintext}
	\begin{caseintext}{2}{\(\asgd{r} \notin \attopt{r}\)}
		We use the monotonicity of valuations for the inequality
		\begin{align}
			\valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r} ]
			&= \valuations[ \attopt{r} \cup \{ \asgd{1}, \dots, \asgd{r} \} ] - \valuations[\asgd{1}, \dots, \asgd{r}] \\
			&\geq \valuations[ \attopt{r} \cup \{ \asgd{1}, \dots, \asgd{r-1} \} ] - \valuations[\asgd{1}, \dots, \asgd{r}] \\
			&= \begin{multlined}[t]
				\paren[\big]{ \valuations[ \attopt{r} \cup \{ \asgd{1}, \dots, \asgd{r-1} \} ] - \valuations[\asgd{1}, \dots, \asgd{r-1}] } \\
				- \paren[\big]{ \valuations[\asgd{1}, \dots, \asgd{r}] - \valuations[\asgd{1}, \dots, \asgd{r-1}] }
			\end{multlined} \\
			&= \valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r-1} ] - \valuations[ \asgd{r} \given \asgd{1}, \dots, \asgd{r-1} ]
		\end{align}
		after first using the submodularity twice to obtain the same lower bound again:\todo{rethink formulation}
		\begin{align}
			\valuations[ \attopt{r+1} \given \asgd{1}, \dots, \asgd{r} ]
			&= \valuations[ \attopt{r} \setminus \lostset{r+1} \given \asgd{1}, \dots, \asgd{r} ] \\
			&\geq \valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r} ] - \valuations[ \lostset{r+1} \given \asgd{1}, \dots, \asgd{r} ] \\
			&\geq \valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r} ] - \valuations[ \lostset{r+1} \given \asgd{1}, \dots, \asgd{r-1} ] \\
			&\geq \begin{multlined}[t]
				\valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r-1} ] - \valuations[ \asgd{r} \given \asgd{1}, \dots, \asgd{r-1} ] \\
				- \valuations[ \lostset{r+1} \given \asgd{1}, \dots, \asgd{r-1} ]
			\end{multlined}
		\end{align}
	\end{caseintext}
	In both cases, we can replace \(\valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r-1} ]\) by the induction hypothesis and \(\valuations[ \lostset{r+1} \given \asgd{1}, \dots, \asgd{r-1} ]\) by \(\lostsetlen{r+1} \cdot \valuations[ \asgd{r} \given \asgd{1}, \dots, \asgd{r-1} ]\) to prove the lemma.
	For a detailed calculation we refer to Garg, Kulkarni and Kulkarni~\cite[14]{APNSWuSVÃ¾UM}.
	\todo{include if space enough}
\end{proof}

The lemma can be used to find a lower bound on the marginal valuation of the items assigned in each round \(r\).
\begin{corollary}
	\label{cor:lower_bound_single_item}
	From \cref{lem:induction} follows
	\begin{equation*}
		\valuations[ \asgd{r} \given \asgd{1}, \dots, \asgd{r-1} ] \geq \begin{multlined}[t]
			\paren[\Big]{ \remvalue* - \lostsetlen{2} \cdot \valuations[\asgd{1}] - \smashoperator{\sum_{r'=2}^{r-1}} \lostsetlen{r'+1} \cdot \valuations[ \asgd{r'} \given \asgd{1}, \dots, \asgd{r'-1} ] \\
				- \valuations[\asgd{1}, \dots, \asgd{r-1}] } \Bigm/ \paren[\Big]{ \attoptlen{0} - \sum_{l = 1}^{r} \lostsetlen{l} }
		\end{multlined}
	\end{equation*}
	where \(\attoptlen{0} \coloneq \abs{\attopt{0}}\) denotes the number of optimal and attainable items after phase \phasei.
\end{corollary}
\begin{proof}
	There are \(\attoptlen{0}\) optimal and attainable items in \(\attopt{0}\) at the start of phase \phaseii.
	Of those, \(\lostsetlen{l}\) many are assigned to other agents in each round \(l \leq r\), and also some items \(\asgd{l}\) assigned to agent \(i\) may be optimal, whence an upper bound of \(\attoptlen{0} - \sum_{l=1}^{r} \lostsetlen{l}\) on the number \(\attoptlen{r}\) of items in the set \(\attopt{r}\).\todo{Possibly this whole estimation can be omitted as we ditch it in the following lemma.}

	The valuations are monotonic, \ie, \(\valuations[\genericset[1]] \leq \valuations[\genericset[2]]\) for all sets \(\genericset[1] \subset \genericset[2] \subset \goods\) of items.
	Induction shows that there must be an item \(j \in \attopt{r}\) with a marginal valuation of at least \(\valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r-1} ] / \attoptlen{r}\).
	As item \(\asgd{r}\) was the one to be assigned, the marginal valuation of it cannot be smaller.
	Using \cref{lem:induction} for the value of \(\valuations[ \attopt{r} \given \asgd{1}, \dots, \asgd{r-1} ]\) proves the corollary.
\end{proof}

This, finally, enables us to give a lower bound on the valuation of the whole bundle assigned in phase \phaseii.
\begin{lemma}
	For each agent \(i \in \agents\) and her bundle \(\alloc[\phaseii] = \{\asgd{1}, \dots, \asgd{\alloclen[\phaseii]}\}\) assigned in phase \phaseii, her valuation \(\valuations[\alloc[\phaseii]]\) of her bundle is lower-bounded by her valuation \(\remvalue* = \valuations[\attopt{1}]\) of the optimal and attainable items in \(\attopt{1}\) after the first round divided by the number \(n\) of agents, \ie,
	\begin{equation*}
		\valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii]}] \geq \remvalue* / n.
	\end{equation*}
\end{lemma}
\begin{proof}
	In each round \(r = 1, \dots, \alloclen[\phaseii]\), \(\lostsetlen{r}\) optimal and attainable items of agent \(i\) are assigned to other agents.
	As there are \(n\) agents in total, \(n-1\) is an upper bound on \(\lostsetlen{r}\).
	Furthermore, after \(\alloclen[\phaseii]\) rounds, the number \(\attoptlen{\alloclen[\phaseii]} \leq \attoptlen{0} - \sum_{l = 1}^{r} \lostsetlen{l}\) of optimal and attainable items is at most \(n-1 \leq n\) else she would have been assigned yet another item.
	Together with \cref{cor:lower_bound_single_item}, this proves the lemma:
	\begin{align}
		\valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii]}]
		&= \valuations[ \asgd{\alloclen[\phaseii]} \given \asgd{1}, \dots, \asgd{\alloclen[\phaseii]} ] + \valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii] - 1}] \\
		&\geq \begin{multlined}[t]
			\paren[\Big]{ \remvalue* - \lostsetlen{2} \cdot \valuations[\asgd{1}]
				- \smashoperator{\sum_{r'=2}^{\alloclen[\phaseii]-1 \mathstrut}} \lostsetlen{r'+1} \cdot \valuations[ \asgd{r'} \given \asgd{1}, \dots, \asgd{r'-1} ] \\
				- \valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii]-1}] } \Big/ \paren[\Big]{ \attoptlen{0} - \sum_{l = 1}^{\alloclen[\phaseii] \mathstrut} \lostsetlen{l} } + \valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii] - 1}]  % \Big/ has better spacing than \Bigm/.
		\end{multlined} \\
		&\geq \begin{multlined}[t]
			\paren[\Big]{ \remvalue* - (n-1) \valuations[\asgd{1}]
				- \smashoperator{\sum_{r'=2}^{\alloclen[\phaseii]-1 \mathstrut}} (n-1) \cdot \valuations[ \asgd{r'} \given \asgd{1}, \dots, \asgd{r'-1} ] \\
				- \valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii]-1}] } \Big/ n + \valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii] - 1}]
		\end{multlined} \\
		&\geq \begin{multlined}[t]
			\paren[\big]{ \remvalue* - (n-1) \valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii]-1}] - \valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii]-1}] } \big/ n \\
			+ \valuations[\asgd{1}, \dots, \asgd{\alloclen[\phaseii] - 1}]
		\end{multlined} \\
		&= \remvalue*/n
	\end{align}
\end{proof}

\begin{remark}
	\todo[inline, inlinewidth=5cm, noinlinepar]{possibly not or shorter}
\end{remark}

After having obtained a lower bound on the valuation of items assigned in phase \phaseii, we need a lower bound for phase \phaseiii{} as well.
To this end, we introduce the concept of \emph{overly good} items, that is items which some agent \(i\) values at least as high as her most valuable optimal item~\(\asgd*{1}\).
The set of overly good items for an agent \(i\) is denoted by
\begin{equation}
	\overlygoodset \coloneq \{\, j \in \goods \given \valuations[j] \geq \valuations[\asgd*{1}] \,\}.
\end{equation}

\begin{lemma}
	\label{lem:overly_good_matching}
	In the beginning of phase \phaseiii, there exists a matching such that each agent \(i \in \agents\) is matched to one of her overly good items in \(\mathop{\bigcup\hspace{-1pt}_{i' \in \agents}} \alloc[\phasei][i']\).
\end{lemma}
\begin{proof}
	\todo[info, inline]{%
		\(\mathbfit{i}\): Due to my departure and my other university obligations, I was unable to finish this proof.
		But I think I got it.
	}
%	Imagine that, in the beginning of phase \phaseiii, only the items which where assigned in the rounds \(1, \dots, t\) of phase \phasei{} were released, for all \(t = 1, \dots, \ceil{\log n}+1\).
%	Choose some matching \(\matching[t]\) which maximises the number of agents matched with one of their overly good items, and denote by \(\unluckyagents\) the set of agents who are \emph{not} matched with one of their overly good items.
%	We prove by induction on the number \(t\) of rounds that it holds \(\abs{\unluckyagents} \leq n/2^t\).
%	The lemma follows since there are \(\ceil{\log_2 n}+1\) rounds in phase \phasei.
%
%	In the base case \(t=1\), none of the items are assigned initially.
%	Denote by \(\unluckyagents[1]\) the number of agents who did not get assigned one of their overly good items in the very first matching computed by \RepReMatch.
%	If \(\unluckyagents[1] \leq n/2\), the base case is obviously proven.
%	Otherwise, all items in the sets \(\overlygoodset\)
%	\begin{caseintext}{2}{\(\abs{\unluckyagents} > n/2\)}
%		All items in the sets \(\overlygoodset\) of overly good items of all \(\unluckyagents\) agents \(i\) must have been assigned to some other agents \(i'\).
%		Each set \(\overlygoodset\) uniquely contains the item \(\asgd*{1}\), so that the size \(\abs{ \mathop{\bigcup\hspace{-1pt}_{i \in \unluckyagents}} \overlygoodset }\) of their union is at least \(\abs{\unluckyagents}\).
%	\end{caseintext}
\end{proof}

\begin{theorem}
	\label{th:reprematch}
	\RepReMatch{} has an approximation factor of \(2n (\log n + 2)\).
\end{theorem}
\begin{proof}
	Because of \cref{lem:overly_good_matching}, we can assign each agent \(i\) an overly good item \(j_i^* \in \overlygoodset\)\todo{fix notation} of hers during the first matching of phase \phaseiii.
	\RepReMatch{} maximises the logarithmic Nash social welfare in that step, so we get
	\begin{equation}
		\log \NSW(\alloc[\phaseiii])
		\geq \frac{1}{\sum_{i \in \agents} \weight} \cdot \sum_{i \in \agents} \weight \log \valuations[j_i^*, \asgd{1}, \dots, \asgd{\alloclen[\phaseii]}]
	\end{equation}
	as lower bound on the \NSW{} after the first matching in phase \phaseiii, whereby \(\alloc[\phaseii] = \{ \asgd{1}, \dots, \asgd{\alloclen[\phaseii]} \}\) is the bundle of agent \(i\) assigned in phase \phaseii.

	\lipsum[16-18]
\end{proof}

\begin{remark}
	\todo[inline, inlinewidth=5cm, noinlinepar]{possibly not or shorter}
\end{remark}

Other text in this section:

\lipsum[19-28]

\begin{algorithm*}[p]
	\KwIn{%
		set \(\agents\) of \(n\) agents with weights \(\weight\) for all agents \(i \in \agents\),
		set \(\goods\) of indivisible \(m\) items,
		submodular valuations \(\valuations \colon \powerset[\goods] \to \realposzero\) where \(\valuations[\genericset]\) is the valuation of agent \(i \in \agents\) for each set \(\genericset \subset \goods\) of items
	}
	\KwOut{%
		\(\frac{1}{2n(\log n + 2)}\)-approximation \(\alloc[\phaseiii][] = (\alloc[\phaseiii][1], \dots, \alloc[\phaseiii][n])\) of an optimal allocation
	}
	\phaseisep
	\(\alloc[\phasei] \gets \emptyset \quad\forall i \in \agents\)\;
	\(\goodsrem \gets \goods\)\;
	\For{\(t \gets 1, \dots, \ceil{\log_2 n}+2\)}{
		\If{\(\goodsrem \neq \emptyset\)}{
			\(\weights \gets \{\,  \weight \cdot \log\paren[\big]{ \valuations[j] } \given[\bigm] i \in \agents, j \in \goodsrem \,\}\)\;
			\(\bipartitegraph \gets (\agents, \goodsrem, \weights)\)\;
			\(\matching \gets \maxweightmatching(\bipartitegraph)\)\;
			\(\alloc[\phasei] \gets \alloc[\phasei] \cup \{j\} \quad \forall(i, j) \in \matching\)\;
			\(\goodsrem \gets \goodsrem \setminus \{\, j \given (i, j) \in \matching \,\}\)\;
		}
	}
	\phaseiisep
	\(\alloc[\phaseii] \gets \emptyset \quad\forall i \in \agents\)   \tct*{put allocation \(\alloc[\phasei][]\) aside and start a new one}
	\While{\(\goodsrem \neq \emptyset\)}{
		\(\weights \gets \{\,  \weight \cdot \log\paren[\big]{ \valuations[ \alloc[\phaseii] \cup \{j\} ] } \given[\bigm] i \in \agents, j \in \goodsrem \,\}\)\;
		\(\bipartitegraph \gets (\agents, \goodsrem, \weights)\)\;
		\(\matching \gets \maxweightmatching(\bipartitegraph)\)\;
		\(\alloc[\phaseii] \gets \alloc[\phaseii] \cup \{j\} \quad \forall(i, j) \in \matching\)\;
		\(\goodsrem \gets \goodsrem \setminus \{\, j \given (i, j) \in \matching \,\}\)\;
	}
	\phaseiiisep
	\(\goodsrem \gets \mathop{\bigcup\hspace{-1pt}_{i \in \agents}} \alloc[\phasei]\)  \tct*{release items assigned in phase \phasei} \label{ln:goodsrem}
	\(\weights \gets \{\,  \weight \cdot \log\paren[\big]{ \valuations[ \alloc[\phaseii] \cup \{j\} ] } \given[\bigm] i \in \agents, j \in \goodsrem \,\}\)\;
	\(\bipartitegraph \gets (\agents, \goodsrem, \weights)\)  \label{ln:bipartitegraph}\;
	\(\matching \gets \maxweightmatching(\bipartitegraph)\)\;
	\(\alloc[\phaseiii] \gets \alloc[\phaseii] \cup \{j\} \quad\forall(i, j) \in \matching\)\;
	\(\goodsrem \gets \goodsrem \setminus \{\, j \given (i, j) \in \matching \,\}\)\;
	\(\alloc[\phaseiii] \gets \arballoc( \agents, \goodsrem, \alloc[\phaseiii], (\valuations)_{i \in \agents} )\)
	\todo{decide on \(\alloc[][]\) or \(\alloc[\phaseiii][]\); discrepancies in orig paper in def of \(\alloc[\phaseiii][]\)!}\;
	\Return{\(\alloc[\phaseiii][]\)}
	\caption{%
		\RepReMatch{} for the Asymmetric Submodular \NSW{} problem
	}
	\label{alg:reprematch}
\end{algorithm*}